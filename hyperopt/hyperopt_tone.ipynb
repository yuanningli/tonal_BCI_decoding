{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1118\n"
     ]
    }
   ],
   "source": [
    "#import transformers\n",
    "#from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import defaultdict\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from functools import partial\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from random import shuffle,randint\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "\n",
    "from scipy.fftpack import fft\n",
    "import scipy.stats as stats\n",
    "import scipy.io as scio\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import word_error_rate as wer\n",
    "from textwrap import wrap\n",
    "import textgrid as tg\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn, optim, einsum\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import wave\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'\n",
    "date='1118'\n",
    "goodmorning=0\n",
    "print(date)\n",
    "subject = 'PA4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEXAMPLE:\\necog_mat,back_duration,forward_duration,mat = read_ecog_mat(back,forward,mat,channelNum,key_elecs=[],\\n                key_label=[],oppolabel=False,key_sentence=[],opposentence=False, key_paragraph=[],oppoparagraph=False,\\n                hz=False, block=4)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FUNCTIONS USED FOR LOAD DATA\n",
    "def get_timelocked_activity(times, hg, back, forward, hz=False):\n",
    "    '''\n",
    "    Get time-locked activity.\n",
    "\n",
    "    Parameters:\n",
    "    - times (array-like): List of timepoints in seconds.\n",
    "    - hg (numpy.ndarray): High gamma array, shaped (elecs_num, whole_duration*hz).\n",
    "    - back (float): Start time before the timepoints.\n",
    "    - forward (float): End time after the timepoints.\n",
    "    - hz (float, optional): Sampling rate of High gamma. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    - Y_mat (numpy.ndarray): Time-locked activity array, shaped (trial_num, elecs_num, selected_duration*hz).\n",
    "    - back (int): Start time in samples (back*hz).\n",
    "    - forward (int): End time in samples (forward*hz).\n",
    "    '''\n",
    "    if hz:\n",
    "        times = (times*hz).astype(int)\n",
    "        back = int(back*hz)\n",
    "        forward = int(forward*hz)\n",
    "    times = times[times - back > 0]\n",
    "    times = times[times + forward < hg.shape[1]]\n",
    "\n",
    "    Y_mat = np.zeros((len(times),hg.shape[0], int(back + forward)), dtype=float)\n",
    "\n",
    "    for i, index in enumerate(times):\n",
    "        Y_mat[i, :, :] = hg[:, int(index-back):int(index+forward)]\n",
    "\n",
    "    return Y_mat,back,forward\n",
    "\n",
    "def read_ecog_mat(back,forward,mat,channelNum,key_elecs=[],key_label=[],oppolabel=False,key_sentence=[],opposentence=False, key_paragraph=[],oppoparagraph=False,\n",
    "                  hz=False, block=4):\n",
    "    '''\n",
    "    get ecog_mat based on defined parameters\n",
    "    \n",
    "    Parameters:\n",
    "    - mat : shaped(7,num_of_timepoints)\n",
    "    - hg (numpy.ndarray): High gamma array, shaped (elecs_num, whole_duration*hz).\n",
    "    - back (float): Start time before the timepoints.\n",
    "    - forward (float): End time after the timepoints.\n",
    "    - hz (float, optional): Sampling rate of High gamma. Default is False.\n",
    "    channelNum:number of electrodes 128 or 256\n",
    "    block:number of blocks included, usually from 1 to 4\n",
    "    key_elecs: selected elecs\n",
    "    kay_labels:selected labels, opplabel means oppose the key_label\n",
    "    sentence and paragraphs similarly\n",
    "    '''\n",
    "\n",
    "    key_elecs = np.array(key_elecs)\n",
    "    key_index = np.ones(len(mat[0,:])).astype('bool')\n",
    "    \n",
    "    sentence_index = np.ones(len(mat[0,:])).astype('bool')\n",
    "    label_index = np.ones(len(mat[0,:])).astype('bool')\n",
    "    paragraph_index = np.ones(len(mat[0,:])).astype('bool')  \n",
    "    \n",
    "    if key_label:\n",
    "        print('select label:'+str(key_label),end=' ')\n",
    "        label_index=~label_index\n",
    "        for i in key_label:\n",
    "            temp_index = mat[0,:] ==i\n",
    "            label_index = np.logical_or(label_index, temp_index)\n",
    "        if oppolabel:\n",
    "            print('oppo')\n",
    "            label_index=~label_index\n",
    "    key_index = np.logical_and(label_index, key_index)\n",
    "    if key_sentence:\n",
    "        print('select sentence:'+str(key_sentence),end=' ')\n",
    "        sentence_index=~sentence_index\n",
    "        for i in key_sentence:\n",
    "            temp_index = mat[2,:] ==i\n",
    "            sentence_index = np.logical_or(sentence_index, temp_index)\n",
    "        if opposentence:\n",
    "            print('oppo')\n",
    "            sentence_index=~sentence_index\n",
    "    key_index = np.logical_and(sentence_index, key_index)        \n",
    "    if key_paragraph:\n",
    "        print('select paraqraph:'+str(key_paragraph),end=' ')\n",
    "        paragraph_index=~paragraph_index\n",
    "        for i in key_paragraph:\n",
    "            temp_index = mat[3,:] ==i\n",
    "            paragraph_index = np.logical_or(paragraph_index, temp_index)\n",
    "        if oppoparagraph:\n",
    "            print('oppo')\n",
    "            paragraph_index=~paragraph_index\n",
    "    key_index = np.logical_and(paragraph_index, key_index)      \n",
    "    mat = mat[:,key_index]\n",
    "       \n",
    "    \n",
    "    if key_elecs.any():\n",
    "        ecog_mat = np.zeros((len(mat[0,:]),len(key_elecs), int((back+forward)*hz)), dtype=float)\n",
    "        print('select elecs:'+str(key_elecs),end=' ')\n",
    "    else:\n",
    "        ecog_mat = np.zeros((len(mat[0,:]),channelNum, int((back+forward)*hz)), dtype=float)\n",
    "        \n",
    "    for i in range(block):\n",
    "        block_index= mat[4,:]==i+1\n",
    "        temp_time_list=mat[1,block_index]\n",
    "        ecogData=scio.loadmat(path_raw+str(i+1)+filterType+'.mat')#################################\n",
    "        ecogData=np.array(ecogData['bands'])*10e4\n",
    "        #print('###',np.nanmean(np.max(ecogData,axis=1)-np.min(ecogData,axis=1)),np.array(np.max(ecogData,axis=1)).shape)######################################################################################\n",
    "        temp_ecog,back_duration,forward_duration = get_timelocked_activity(times=temp_time_list, hg=ecogData, back=back, forward=forward, hz=hz)\n",
    "        if key_elecs.any():\n",
    "            key_elecs = np.array(key_elecs)\n",
    "            ecog_mat[block_index] = temp_ecog[:,key_elecs,:]\n",
    "        else:\n",
    "            ecog_mat[block_index] = temp_ecog\n",
    "\n",
    "    print('read_ecog:',ecog_mat.shape)\n",
    "    return ecog_mat,back_duration,forward_duration,mat\n",
    "\n",
    "'''\n",
    "EXAMPLE:\n",
    "ecog_mat,back_duration,forward_duration,mat = read_ecog_mat(back,forward,mat,channelNum,key_elecs=[],\n",
    "                key_label=[],oppolabel=False,key_sentence=[],opposentence=False, key_paragraph=[],oppoparagraph=False,\n",
    "                hz=False, block=4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS USED FOR TRAIN AND VALIDATE THE MODEL\n",
    "\n",
    "def evaluater(Mat, prob_list, loss_func = nn.CrossEntropyLoss(), unit = 3):\n",
    "    \n",
    "    if stage in ['sylb','onset_sylb']:\n",
    "        List = sylbList\n",
    "        row = 0\n",
    "    elif stage in ['tone','onset_tone']:\n",
    "        List = toneList\n",
    "        row = 5\n",
    "        \n",
    "    real_indices = np.where(~np.isnan(Mat[0, :]))[0]\n",
    "    Mat =  Mat[:, real_indices]\n",
    "    prob_list = np.array(prob_list)[np.array(real_indices)]\n",
    "    \n",
    "    acc_list=[]\n",
    "    loss_list=[]\n",
    "    for trial in set(Mat[unit,:]):\n",
    "        trial_index = Mat[3,:]==trial\n",
    "        temp_label = Mat[row,trial_index]\n",
    "        temp_prob = prob_list[trial_index]\n",
    "\n",
    "        loss = loss_func(torch.tensor(temp_prob), torch.tensor(temp_label, dtype=torch.long))\n",
    "        loss = loss / len(temp_label)\n",
    "        temp_out = np.argmax(temp_prob, axis=1)\n",
    "        correct = np.sum(temp_out == np.array(temp_label))\n",
    "        acc = correct / len(temp_label)\n",
    "\n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(loss)\n",
    "    \n",
    "    if plot:\n",
    "        plotCM(List, acc_list, Mat[row,:], np.argmax(prob_list, axis=1))\n",
    "\n",
    "    return acc_list, loss_list\n",
    "\n",
    "def CV_datasets(back,forward,mat,key_elecs,row,CV_list,unbalance=False,List=False,augmented=False):\n",
    "    #split data to cross validation combinations, and calculate the weight of each labels\n",
    "    CV_datasets = []\n",
    "    CV_augmented_datasets=[]\n",
    "    count_total=[]\n",
    "\n",
    "    for CVs in range(6):\n",
    "        print('mat:',mat.shape)\n",
    "        test_ecog_mat,_,_,test_mat= read_ecog_mat(back=back,forward=forward,mat=mat,channelNum=channelNum,key_elecs=key_elecs,\n",
    "                key_label=[],oppolabel=False,key_sentence=[],opposentence=False, key_paragraph=CV_list[CVs],oppoparagraph=False,\n",
    "                hz=hz, block=4)\n",
    "\n",
    "        test_label = test_mat[row,:]\n",
    "        \n",
    "        if unbalance == True:\n",
    "            count=np.bincount(test_label.astype('int'))\n",
    "            if len(count)!=len(List):\n",
    "                #triggerrd when there are some blocks without all the labels\n",
    "                print('not a full set!')\n",
    "            print(count)\n",
    "            count_total.append(count)\n",
    "        test_ecog_mat=torch.FloatTensor(test_ecog_mat)\n",
    "        test_label=torch.tensor(test_label,dtype=torch.long)\n",
    "        testdataset = Data.TensorDataset(test_ecog_mat, test_label)    \n",
    "        CV_datasets.append(testdataset)\n",
    "        \n",
    "\n",
    "        if augmented is not False:\n",
    "            aug_mat = stammer (mat=test_mat, multiple_time=augmented,multiple_range=0.1,shift=-0.05)\n",
    "            aug_ecog_mat,_,_,test_mat= read_ecog_mat(back=back,forward=forward,mat=mat,channelNum=channelNum,key_elecs=key_elecs,\n",
    "                key_label=[],oppolabel=False,key_sentence=[],opposentence=False, key_paragraph=CV_list[CVs],oppoparagraph=False,\n",
    "                hz=hz, block=4)\n",
    "            aug_label = aug_mat[row,:]\n",
    "            aug_ecog_mat=torch.FloatTensor(aug_ecog_mat)\n",
    "            aug_label=torch.tensor(aug_label,dtype=torch.long)\n",
    "            augdataset = Data.TensorDataset(aug_ecog_mat, aug_label) \n",
    "            CV_augmented_datasets.append(augdataset)\n",
    "            \n",
    "    if unbalance == True:\n",
    "        count_total = np.array(count_total)\n",
    "        \n",
    "    return CV_datasets,count_total,CV_augmented_datasets\n",
    "\n",
    "'''\n",
    "EXAMPLES:\n",
    "CV_onset_datasets,count_total,_ = CV_datasets(back=overt_back,\n",
    "                                            forward=overt_forward,\n",
    "                                            mat=overt_mat,\n",
    "                                            key_elecs=overt_elecs,\n",
    "                                            row=0,\n",
    "                                            CV_list,\n",
    "                                            unbalance=True,List=stateList,\n",
    "                                            augmented=False)\n",
    "class_weight = np.sum(count_total,axis=0)\n",
    "'''\n",
    "'''\n",
    "CV_sylb_datasets,_,_ = CV_datasets(back=sylb_back,\n",
    "                            forward=sylb_forward,\n",
    "                            mat=sylb_mat,\n",
    "                            key_elecs=sylb_elecs,\n",
    "                            row=0,\n",
    "                            CV_list,\n",
    "                            unbalance=False,List=False,\n",
    "                            augmented=False)\n",
    "'''\n",
    "'''\n",
    "CV_clip_datasets,_,_ = CV_datasets(back=sylb_back,\n",
    "                            forward=sylb_forward,\n",
    "                            mat=clipTimeMat,\n",
    "                            key_elecs=sylb_elecs,\n",
    "                            row=0,\n",
    "                            CV_list,\n",
    "                            unbalance=False,List=False,\n",
    "                            augmented=False)\n",
    "\n",
    "'''\n",
    "def CV_train_ENN(CV_datasets, CV_pred_only_datasets, lr, batch_size, patience,\n",
    "                 class_weight = False, channelNum=256,plot = False):\n",
    "    #this is used for cross validation on ensumble models \n",
    "    test_out_prob_list=[]\n",
    "    pred_only_prob_list=[]\n",
    "    torch.cuda.empty_cache()\n",
    "    for test_CV in range(6):#tqdm(\n",
    "        CV_train_val_datasets = CV_datasets.copy()\n",
    "        CV_test_datasets = [CV_train_val_datasets.pop(test_CV),]\n",
    "        pred_only_datasets = [CV_pred_only_datasets[test_CV],]\n",
    "        #model_list=[]\n",
    "        predicted_prob_list = []\n",
    "        predicted_only_prob_list= []\n",
    "        for CVs in range(5):\n",
    "            CV_train_datasets = CV_train_val_datasets.copy()\n",
    "            CV_val_datasets = [CV_train_datasets.pop(CVs),]\n",
    "            #label,acc,predicted,predicted_prob, predicted_only,predicted_only_prob,model\n",
    "            _,_,_,predicted_prob,_,predicted_only_prob,CV_model,loss_func = train( \n",
    "                                        lr=lr, batch_size=batch_size, EPOCH=EPOCH, patience=patience, \n",
    "                                        CV_train_datasets = CV_train_datasets, #CV_train_val_datasets, #\n",
    "                                        CV_val_datasets =  CV_val_datasets, #False, #\n",
    "                                        CV_test_datasets = CV_test_datasets,#False, \n",
    "                                        pred_only_datasets = pred_only_datasets, \n",
    "                                        class_weight=class_weight)\n",
    "            \n",
    "            #model_list.append(CV_model)\n",
    "            predicted_prob_list.append(predicted_prob)\n",
    "            predicted_only_prob_list.append(predicted_only_prob)\n",
    "        \n",
    "        predicted_prob = np.mean(predicted_prob_list, axis=0)\n",
    "        test_out_prob_list.extend(predicted_prob)\n",
    "        predicted_only_prob = np.mean(predicted_only_prob_list, axis=0)\n",
    "        pred_only_prob_list.extend(predicted_only_prob) \n",
    "        \n",
    "    a, acc_list = evaluater(sylb_label_mat, test_out_prob_list, loss_func = loss_func, unit = 3)    \n",
    "    if not verbose:\n",
    "        print(str(a))\n",
    "    _, loss_list = evaluater(clipTimeMat, pred_only_prob_list, loss_func = loss_func, unit = 3)\n",
    "    \n",
    "    return [acc_list, loss_list], test_out_prob_list, pred_only_prob_list\n",
    "\n",
    "def train(batch_size, lr, EPOCH, patience, CV_train_datasets, \n",
    "          CV_val_datasets=False, CV_test_datasets=False, pred_only_datasets=False, \n",
    "          class_weight=False):\n",
    "    #This function directly train and validate the model\n",
    "    model = torch.load(\"./\"+subject+'.pt')\n",
    "    loss_func = nn.CrossEntropyLoss() \n",
    "    if class_weight is not False:\n",
    "        weight = [max(class_weight)/x for x in class_weight]\n",
    "        weight = torch.FloatTensor(weight).to(device)\n",
    "        loss_func = nn.CrossEntropyLoss(weight=weight)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)#也可以使用SGD优化算法进行训练\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience)\n",
    "    '''\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr=lr)#也可以使用SGD优化算法进行训练\n",
    "    scheduler =  torch.optim.lr_scheduler.CosineAnnealingLR(optimizer = optimizer,T_max =  EPOCH)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=patience, \n",
    "                                           verbose=False, threshold=0.0001, threshold_mode='rel', \n",
    "                                           cooldown=0, min_lr=0, eps=1e-08)\n",
    "    '''\n",
    "    for epoch in range(EPOCH):\n",
    "        #return acc，ground truth & predicited label\n",
    "        sum_loss_train= 0\n",
    "        total_train=0\n",
    "        model.train()\n",
    "        for train_dataset in CV_train_datasets:\n",
    "            train_loader = Data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            for data in train_loader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(inputs)\n",
    "                loss = loss_func(pred, labels)\n",
    "                sum_loss_train+= loss.item()\n",
    "                total_train+= labels.size(0)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        train_loss = sum_loss_train/total_train\n",
    "        if verbose:\n",
    "            print('Epoch {}:train-loss:{:.2e},'.format(epoch+1,train_loss),end='')\n",
    "       \n",
    "        if CV_val_datasets is not False:#if there is val datasets performing early-stopping\n",
    "            sum_loss_val=0\n",
    "            total_val = 0  \n",
    "            for val_dataset in CV_val_datasets:\n",
    "                val_loader = Data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = inputs.to(device), labels.to(device) \n",
    "                    pred = model(inputs)\n",
    "                    loss = loss_func(pred, labels)\n",
    "                    sum_loss_val+=loss.item()\n",
    "                    total_val+= labels.size(0)\n",
    "            val_loss = sum_loss_val/total_val\n",
    "            if verbose:\n",
    "                print('val-loss:{:.2e},'.format(val_loss,),end='')\n",
    "            \n",
    "            '''\n",
    "            scheduler.step(val_loss)##############################################\n",
    "            #scheduler.step()\n",
    "            '''\n",
    "            early_stopping(val_loss, model)\n",
    "            if early_stopping.early_stop:\n",
    "                if verbose:\n",
    "                    print(\"Early stopping\")\n",
    "                break\n",
    "        \n",
    "        if CV_test_datasets is not False: #if there is test data for testing\n",
    "            total_test = 0  \n",
    "            sum_loss_test= 0\n",
    "            predicted=[]\n",
    "            label=[]\n",
    "            \n",
    "            for test_dataset in CV_test_datasets:\n",
    "                test_loader = Data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "                for data in test_loader:\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    pred_prob = model(inputs)\n",
    "                    loss = loss_func(pred_prob, labels)\n",
    "                    sum_loss_test+=loss.item()\n",
    "                    _, pred = torch.max(pred_prob.data, 1)\n",
    "                    pred_prob = pred_prob.data\n",
    "                    pred_prob = F.softmax(pred_prob, dim=1) \n",
    "                    total_test+= labels.size(0)\n",
    "                    predicted.append(pred.cpu())\n",
    "                    label.append(labels.cpu())\n",
    "            label = torch.cat(label,dim=0)\n",
    "            predicted = torch.cat(predicted,dim=0)\n",
    "            correct = (predicted == label).sum()\n",
    "            test_acc= correct.item()/total_test\n",
    "            test_loss=sum_loss_test/total_test\n",
    "            if verbose:\n",
    "                print('test-loss:{:.2e},Acc:{:.4f}'.format(test_loss,test_acc),end='')\n",
    "        if verbose:\n",
    "            print('')\n",
    "    \n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "    \n",
    "    ##############################EVALUATION model###############################################\n",
    "    predicted=[]\n",
    "    predicted_prob=[]\n",
    "    label=[]\n",
    "    acc=[]\n",
    "    if CV_test_datasets is not False:\n",
    "        total_test = 0  # 总数\n",
    "        sum_loss_test= 0\n",
    "        model.eval()\n",
    "        for test_dataset in CV_test_datasets:\n",
    "            test_loader = Data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "            for data in test_loader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)  # 有GPU则将数据置入GPU加速\n",
    "                pred_prob = model(inputs)\n",
    "                loss = loss_func(pred_prob, labels)\n",
    "                sum_loss_test+=loss.item()\n",
    "                _, pred = torch.max(pred_prob.data, 1)\n",
    "                pred_prob = pred_prob.data\n",
    "                pred_prob = F.softmax(pred_prob, dim=1) \n",
    "                total_test+= labels.size(0)\n",
    "\n",
    "                predicted.append(pred.cpu())\n",
    "                predicted_prob.append(pred_prob.cpu())\n",
    "                label.append(labels.cpu())\n",
    "\n",
    "        label = torch.cat(label,dim=0)\n",
    "        predicted = torch.cat(predicted,dim=0)\n",
    "        predicted_prob = torch.cat(predicted_prob,dim=0)\n",
    "        correct = (predicted == label).sum()\n",
    "        test_acc= correct.item()/total_test\n",
    "        test_loss=sum_loss_test/total_test\n",
    "        if verbose:\n",
    "            print('Final: test-loss:{:.2e},Acc:{:.4f}'.format(test_loss,test_acc))\n",
    "        label = label.detach().numpy()\n",
    "        acc = test_acc\n",
    "        predicted = predicted.detach().numpy()\n",
    "        predicted_prob = predicted_prob.detach().numpy()\n",
    "    \n",
    "    \n",
    "    ##PRED-ONLY:do not return acc, only predicted result\n",
    "    predicted_only=[]\n",
    "    predicted_only_prob=[]\n",
    "        \n",
    "    if pred_only_datasets is not False:\n",
    "        for pred_only_dataset in pred_only_datasets:\n",
    "            pred_only_loader = Data.DataLoader(pred_only_dataset, batch_size=batch_size, shuffle=False)\n",
    "            for inputs in pred_only_loader:\n",
    "                inputs = inputs[0].to(device)\n",
    "                pred = model(inputs)\n",
    "                pred_only_prob = pred.data\n",
    "                pred_only_prob = F.softmax(pred_only_prob, dim=1) \n",
    "                _, pred_only = torch.max(pred.data, 1)\n",
    "                predicted_only.append(pred_only.cpu())\n",
    "                predicted_only_prob.append(pred_only_prob.cpu())\n",
    "            \n",
    "        predicted_only = torch.cat(predicted_only).detach().numpy()\n",
    "        predicted_only_prob = torch.cat(predicted_only_prob).detach().numpy()\n",
    "        if verbose:\n",
    "            print(predicted_only_prob.shape)\n",
    "    \n",
    "    return label,acc, predicted,predicted_prob, predicted_only,predicted_only_prob, model,loss_func.cpu()\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping: {self.counter}/{self.patience}',end='')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\t# save the best model\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1034)\n",
      "select paraqraph:[13, 14, 15, 16] oppo\n",
      "select elecs:[1] read_ecog: (775, 1, 8)\n",
      "(7, 768)\n"
     ]
    }
   ],
   "source": [
    "path_raw='../Raw/B'\n",
    "\n",
    "sylbList = ['shi', 'de', 'ji', 'li', 'bu', 'ge', 'qi', 'zhe', 'ta', 'zhi']\n",
    "stateList=['silent','speech']\n",
    "toneList = ['1','2','3','4']\n",
    "hz = 400\n",
    "filterType = '_70_150'\n",
    "channelNum = 256\n",
    "sylb_mat = np.load('../'+subject+'_sylb_mat'+'.npy',allow_pickle=True)\n",
    "print(sylb_mat.shape)\n",
    "_,_,_,sylb_label_mat =  read_ecog_mat(0.01,0.01,sylb_mat,channelNum=256,key_elecs=[1,],\n",
    "                key_label=[],oppolabel=False,key_sentence=[],opposentence=False, \n",
    "                key_paragraph=[13,14,15,16],oppoparagraph=True,hz=hz, block=4)\n",
    "clipTimeMat = np.load(subject+'_opt_clipTimeMat'+'.npy',allow_pickle=True)\n",
    "print(clipTimeMat.shape)\n",
    "\n",
    "channelNum = 256\n",
    "tone_back = 0.2\n",
    "tone_forward = 0.6\n",
    "\n",
    "CV_list=[[1,2],[3,4],[5,6],[7,8],[9,10],[11,12]]\n",
    "tone_elecs = np.load('../'+subject+'_anovatone_elecs.npy')\n",
    "row=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat: (7, 1034)\n",
      "select paraqraph:[1, 2] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (133, 48, 320)\n",
      "[43 29 17 44]\n",
      "mat: (7, 1034)\n",
      "select paraqraph:[3, 4] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (132, 48, 320)\n",
      "[47 27 16 42]\n",
      "mat: (7, 1034)\n",
      "select paraqraph:[5, 6] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (125, 48, 320)\n",
      "[43 28 15 39]\n",
      "mat: (7, 1034)\n",
      "select paraqraph:[7, 8] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (129, 48, 320)\n",
      "[46 26 16 41]\n",
      "mat: (7, 1034)\n",
      "select paraqraph:[9, 10] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (124, 48, 320)\n",
      "[41 26 15 42]\n",
      "mat: (7, 1034)\n",
      "select paraqraph:[11, 12] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (132, 48, 320)\n",
      "[42 28 16 46]\n",
      "mat: (7, 768)\n",
      "select paraqraph:[1, 2] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (132, 48, 320)\n",
      "mat: (7, 768)\n",
      "select paraqraph:[3, 4] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (130, 48, 320)\n",
      "mat: (7, 768)\n",
      "select paraqraph:[5, 6] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (126, 48, 320)\n",
      "mat: (7, 768)\n",
      "select paraqraph:[7, 8] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (127, 48, 320)\n",
      "mat: (7, 768)\n",
      "select paraqraph:[9, 10] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (123, 48, 320)\n",
      "mat: (7, 768)\n",
      "select paraqraph:[11, 12] select elecs:[  0   1   2   5   8   9  13  14  15  32  46  48  59  75  78  95  96 100\n",
      " 110 111 112 136 137 151 152 156 166 167 168 171 172 174 181 183 188 189\n",
      " 197 198 199 204 211 214 226 228 230 242 253 254] read_ecog: (130, 48, 320)\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "CV_tone_datasets,count_total,_ = CV_datasets(back=tone_back,\n",
    "                                            forward=tone_forward,\n",
    "                                            mat=sylb_mat,\n",
    "                                            key_elecs=tone_elecs,\n",
    "                                            row=5,\n",
    "                                            CV_list=CV_list,\n",
    "                                            unbalance=True,List=toneList,\n",
    "                                            augmented=False)\n",
    "class_weight = np.sum(count_total,axis=0)\n",
    "'''\n",
    "'''\n",
    "CV_clip_tone_datasets,_,_ = CV_datasets(back=tone_back,\n",
    "                            forward=tone_forward,\n",
    "                            mat=clipTimeMat,\n",
    "                            key_elecs=tone_elecs,\n",
    "                            row=5,\n",
    "                            CV_list=CV_list,\n",
    "                            unbalance=False,List=False,\n",
    "                            augmented=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class timespatCNNRNN(nn.Module):\n",
    "    def __init__(self, *, duration, typeNum, in_chans, is_timespat,\n",
    "                 n_filters_time,\n",
    "                 filter_time_length,\n",
    "                 n_filters_spat,\n",
    "                 conv_stride,\n",
    "                 pool_time_length,\n",
    "                 pool_stride,\n",
    "                 n_filters,\n",
    "                 filter_length, \n",
    "                 n_CNN_layer,\n",
    "                 gruDim,\n",
    "                 gruLayer,\n",
    "                 drop_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_time = nn.Conv2d(\n",
    "            1,\n",
    "            n_filters_time,\n",
    "            (filter_time_length, 1),\n",
    "            stride=1,\n",
    "        )\n",
    "        \n",
    "        self.conv_spat = nn.Conv2d(\n",
    "            n_filters_time,\n",
    "            n_filters_spat,\n",
    "            (1, in_chans),\n",
    "            stride=(conv_stride, 1),\n",
    "        )\n",
    "        self.is_timespat = is_timespat\n",
    "        self.conv_timespat = nn.Conv2d(\n",
    "            1,\n",
    "            n_filters_spat,\n",
    "            (filter_time_length, in_chans),\n",
    "            stride=(conv_stride, 1),\n",
    "        )\n",
    "        \n",
    "        self.bnorm = nn.BatchNorm2d(\n",
    "            n_filters_spat,\n",
    "            #momentum=self.batch_norm_alpha,\n",
    "            affine=True,\n",
    "            eps=1e-5)\n",
    "        self.elu = nn.ELU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(pool_time_length, 1), stride=(pool_stride, 1))\n",
    "        \n",
    "        self.conv_pool_block = nn.ModuleList()\n",
    "        self.conv_pool_block.append(nn.Dropout(p=drop_out))\n",
    "        self.conv_pool_block.append(nn.Conv2d(\n",
    "            n_filters_spat,\n",
    "            n_filters,\n",
    "            (filter_length, 1),\n",
    "            stride=(conv_stride, 1),\n",
    "            padding=(((filter_length - 1) * conv_stride) // 2,0)\n",
    "        ))\n",
    "        \n",
    "        for i in range(n_CNN_layer-1):\n",
    "            self.conv_pool_block.append(nn.Dropout(p=drop_out))\n",
    "            self.conv_pool_block.append(nn.Conv2d(\n",
    "                n_filters,\n",
    "                n_filters,\n",
    "                (filter_length, 1),\n",
    "                stride=(conv_stride, 1),\n",
    "                padding=(((filter_length - 1) * conv_stride) // 2,0)\n",
    "            ))\n",
    "            self.conv_pool_block.append(nn.BatchNorm2d(\n",
    "                n_filters,\n",
    "                momentum=0.1,\n",
    "                affine=True,\n",
    "                eps=1e-5,\n",
    "            ))\n",
    "            self.conv_pool_block.append(nn.ELU())\n",
    "            self.conv_pool_block.append(nn.MaxPool2d(\n",
    "                kernel_size=(pool_time_length, 1),\n",
    "                stride=(pool_stride, 1),\n",
    "            ))\n",
    "\n",
    "        self.gru1 = nn.GRU(n_filters, gruDim, gruLayer, batch_first=True, bidirectional=True)\n",
    "        elec_feature = int(2*gruDim)\n",
    "        self.fc1 = nn.Linear(elec_feature, typeNum)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x,'(batch 1) electrodes duration -> batch 1 duration electrodes')\n",
    "        if self.is_timespat:\n",
    "            x = self.conv_timespat(x)\n",
    "        else:\n",
    "            x = self.conv_time(x)\n",
    "            #print('1',x.shape)\n",
    "            x = self.conv_spat(x)\n",
    "        #print('2',x.shape)\n",
    "        x = self.bnorm(x)\n",
    "        x = self.elu(x)\n",
    "        x = self.pool(x)\n",
    "        for block in self.conv_pool_block:\n",
    "            x = block(x)\n",
    "        x = rearrange(x,'batch filter duration 1 -> batch duration filter')\n",
    "        x = self.gru1(x)[0][:,-1,:]\n",
    "        #x = self.relu1(x) \n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40298507462686567, 0.3787878787878788, 0.3181818181818182, 0.3333333333333333, 0.4090909090909091, 0.4576271186440678, 0.5303030303030303, 0.42857142857142855, 0.4576271186440678, 0.4, 0.4696969696969697, 0.3787878787878788]\n",
      "[0.22388059701492538, 0.25757575757575757, 0.12121212121212122, 0.12121212121212122, 0.24242424242424243, 0.22033898305084745, 0.21212121212121213, 0.20634920634920634, 0.11864406779661017, 0.12307692307692308, 0.25757575757575757, 0.25757575757575757]\n",
      "[0.3880597014925373, 0.42424242424242425, 0.5, 0.5303030303030303, 0.5, 0.6101694915254238, 0.5151515151515151, 0.5238095238095238, 0.559322033898305, 0.7230769230769231, 0.5303030303030303, 0.45454545454545453]\n",
      "[0.4925373134328358, 0.5454545454545454, 0.6212121212121212, 0.7272727272727273, 0.5303030303030303, 0.711864406779661, 0.5303030303030303, 0.5714285714285714, 0.5254237288135594, 0.5846153846153846, 0.5757575757575758, 0.4090909090909091]\n",
      "[0.373134328358209, 0.5606060606060606, 0.4696969696969697, 0.5151515151515151, 0.48484848484848486, 0.6779661016949152, 0.4696969696969697, 0.5079365079365079, 0.5254237288135594, 0.5538461538461539, 0.42424242424242425, 0.4090909090909091]\n",
      "[0.43283582089552236, 0.48484848484848486, 0.6363636363636364, 0.6060606060606061, 0.48484848484848486, 0.576271186440678, 0.6363636363636364, 0.5238095238095238, 0.559322033898305, 0.5230769230769231, 0.42424242424242425, 0.3787878787878788]\n",
      "[0.43283582089552236, 0.4696969696969697, 0.7424242424242424, 0.803030303030303, 0.5151515151515151, 0.6101694915254238, 0.5303030303030303, 0.49206349206349204, 0.423728813559322, 0.6, 0.5151515151515151, 0.4090909090909091]\n",
      "[0.5223880597014925, 0.3939393939393939, 0.6515151515151515, 0.7575757575757576, 0.48484848484848486, 0.4915254237288136, 0.5454545454545454, 0.4603174603174603, 0.4067796610169492, 0.46153846153846156, 0.3787878787878788, 0.4090909090909091]\n",
      "[0.43283582089552236, 0.4090909090909091, 0.5, 0.696969696969697, 0.5151515151515151, 0.6949152542372882, 0.5151515151515151, 0.49206349206349204, 0.5084745762711864, 0.6153846153846154, 0.4090909090909091, 0.3787878787878788]\n",
      "[0.3283582089552239, 0.3484848484848485, 0.4696969696969697, 0.4696969696969697, 0.5151515151515151, 0.6271186440677966, 0.5, 0.4444444444444444, 0.3728813559322034, 0.49230769230769234, 0.3333333333333333, 0.3939393939393939]\n",
      "[0.5373134328358209, 0.5909090909090909, 0.2727272727272727, 0.2878787878787879, 0.4393939393939394, 0.4915254237288136, 0.36363636363636365, 0.42857142857142855, 0.4406779661016949, 0.4461538461538462, 0.36363636363636365, 0.3181818181818182]\n",
      "[0.43283582089552236, 0.45454545454545453, 0.3787878787878788, 0.4090909090909091, 0.5909090909090909, 0.6271186440677966, 0.5303030303030303, 0.5079365079365079, 0.4406779661016949, 0.47692307692307695, 0.42424242424242425, 0.5]\n",
      "[0.40298507462686567, 0.5909090909090909, 0.5454545454545454, 0.5606060606060606, 0.3939393939393939, 0.6101694915254238, 0.5606060606060606, 0.5396825396825397, 0.4915254237288136, 0.5230769230769231, 0.5151515151515151, 0.45454545454545453]\n",
      "[0.40298507462686567, 0.4696969696969697, 0.45454545454545453, 0.48484848484848486, 0.4696969696969697, 0.576271186440678, 0.45454545454545453, 0.4603174603174603, 0.3728813559322034, 0.5384615384615384, 0.42424242424242425, 0.3484848484848485]\n",
      "[0.44776119402985076, 0.4696969696969697, 0.45454545454545453, 0.48484848484848486, 0.5606060606060606, 0.6440677966101694, 0.6060606060606061, 0.6507936507936508, 0.5084745762711864, 0.5692307692307692, 0.5151515151515151, 0.4393939393939394]\n",
      "[0.40298507462686567, 0.48484848484848486, 0.5303030303030303, 0.6212121212121212, 0.5303030303030303, 0.6949152542372882, 0.5151515151515151, 0.5873015873015873, 0.4576271186440678, 0.6461538461538462, 0.5757575757575758, 0.5]\n",
      "[0.417910447761194, 0.45454545454545453, 0.6060606060606061, 0.5909090909090909, 0.5303030303030303, 0.5932203389830508, 0.5757575757575758, 0.5714285714285714, 0.5423728813559322, 0.5692307692307692, 0.5, 0.3787878787878788]\n",
      "[0.417910447761194, 0.5303030303030303, 0.696969696969697, 0.696969696969697, 0.5606060606060606, 0.6610169491525424, 0.6060606060606061, 0.6349206349206349, 0.5254237288135594, 0.6, 0.6060606060606061, 0.4090909090909091]\n",
      "[0.3880597014925373, 0.42424242424242425, 0.5151515151515151, 0.5606060606060606, 0.45454545454545453, 0.6440677966101694, 0.5151515151515151, 0.5555555555555556, 0.559322033898305, 0.6923076923076923, 0.4696969696969697, 0.4696969696969697]\n",
      "[0.5074626865671642, 0.5606060606060606, 0.6212121212121212, 0.7272727272727273, 0.48484848484848486, 0.6610169491525424, 0.6212121212121212, 0.5396825396825397, 0.5254237288135594, 0.6615384615384615, 0.6363636363636364, 0.4696969696969697]\n",
      "[0.3880597014925373, 0.5, 0.48484848484848486, 0.48484848484848486, 0.5151515151515151, 0.5932203389830508, 0.4393939393939394, 0.5079365079365079, 0.423728813559322, 0.5846153846153846, 0.5303030303030303, 0.42424242424242425]\n",
      "Error: Given input size: (32x3x1). Calculated output size: (32x0x1). Output size is too small\n",
      "[0.5223880597014925, 0.5454545454545454, 0.5606060606060606, 0.6363636363636364, 0.5909090909090909, 0.6779661016949152, 0.5909090909090909, 0.6349206349206349, 0.4745762711864407, 0.6461538461538462, 0.6212121212121212, 0.4696969696969697]\n",
      "[0.3880597014925373, 0.48484848484848486, 0.5303030303030303, 0.5909090909090909, 0.45454545454545453, 0.4745762711864407, 0.42424242424242425, 0.5079365079365079, 0.4406779661016949, 0.5384615384615384, 0.5757575757575758, 0.30303030303030304]\n",
      "[0.417910447761194, 0.5, 0.5, 0.6060606060606061, 0.5303030303030303, 0.6440677966101694, 0.5454545454545454, 0.5238095238095238, 0.4745762711864407, 0.6615384615384615, 0.48484848484848486, 0.45454545454545453]\n",
      "[0.3880597014925373, 0.4696969696969697, 0.4696969696969697, 0.5606060606060606, 0.45454545454545453, 0.6440677966101694, 0.5606060606060606, 0.5873015873015873, 0.4915254237288136, 0.6, 0.5151515151515151, 0.5]\n",
      "[0.40298507462686567, 0.4090909090909091, 0.48484848484848486, 0.5757575757575758, 0.48484848484848486, 0.6949152542372882, 0.6212121212121212, 0.5714285714285714, 0.4915254237288136, 0.6461538461538462, 0.5303030303030303, 0.4696969696969697]\n",
      "[0.43283582089552236, 0.5606060606060606, 0.6060606060606061, 0.6818181818181818, 0.5606060606060606, 0.6779661016949152, 0.5454545454545454, 0.5079365079365079, 0.5423728813559322, 0.7076923076923077, 0.5, 0.45454545454545453]\n",
      "[0.43283582089552236, 0.3787878787878788, 0.6060606060606061, 0.6212121212121212, 0.5303030303030303, 0.6949152542372882, 0.6212121212121212, 0.5238095238095238, 0.5254237288135594, 0.676923076923077, 0.5909090909090909, 0.4090909090909091]\n",
      "[0.40298507462686567, 0.5151515151515151, 0.42424242424242425, 0.4393939393939394, 0.48484848484848486, 0.6101694915254238, 0.5303030303030303, 0.49206349206349204, 0.4915254237288136, 0.6923076923076923, 0.5303030303030303, 0.42424242424242425]\n",
      "[0.44776119402985076, 0.48484848484848486, 0.5454545454545454, 0.6818181818181818, 0.48484848484848486, 0.6610169491525424, 0.5909090909090909, 0.5873015873015873, 0.559322033898305, 0.7384615384615385, 0.5757575757575758, 0.4090909090909091]\n",
      "[0.373134328358209, 0.45454545454545453, 0.48484848484848486, 0.5151515151515151, 0.5454545454545454, 0.6101694915254238, 0.5303030303030303, 0.5555555555555556, 0.5084745762711864, 0.38461538461538464, 0.48484848484848486, 0.42424242424242425]\n",
      "[0.373134328358209, 0.4090909090909091, 0.4393939393939394, 0.36363636363636365, 0.3939393939393939, 0.6779661016949152, 0.5909090909090909, 0.5238095238095238, 0.4406779661016949, 0.6923076923076923, 0.6515151515151515, 0.5]\n",
      "[0.4626865671641791, 0.5454545454545454, 0.5, 0.5303030303030303, 0.5757575757575758, 0.711864406779661, 0.5151515151515151, 0.6190476190476191, 0.4915254237288136, 0.6307692307692307, 0.6363636363636364, 0.4696969696969697]\n",
      "[0.3880597014925373, 0.3787878787878788, 0.4696969696969697, 0.45454545454545453, 0.5, 0.6610169491525424, 0.45454545454545453, 0.5555555555555556, 0.4915254237288136, 0.5692307692307692, 0.5151515151515151, 0.5]\n",
      "[0.44776119402985076, 0.3939393939393939, 0.5606060606060606, 0.6060606060606061, 0.5151515151515151, 0.7457627118644068, 0.5151515151515151, 0.5873015873015873, 0.4576271186440678, 0.7076923076923077, 0.5909090909090909, 0.4696969696969697]\n",
      "[0.40298507462686567, 0.4696969696969697, 0.5303030303030303, 0.5303030303030303, 0.5757575757575758, 0.6610169491525424, 0.5151515151515151, 0.6031746031746031, 0.576271186440678, 0.676923076923077, 0.6666666666666666, 0.45454545454545453]\n",
      "[0.43283582089552236, 0.45454545454545453, 0.5, 0.5909090909090909, 0.5757575757575758, 0.6949152542372882, 0.5606060606060606, 0.5873015873015873, 0.4745762711864407, 0.6307692307692307, 0.5606060606060606, 0.5151515151515151]\n",
      "[0.23880597014925373, 0.24242424242424243, 0.24242424242424243, 0.3939393939393939, 0.3939393939393939, 0.576271186440678, 0.3787878787878788, 0.4444444444444444, 0.4745762711864407, 0.4461538461538462, 0.45454545454545453, 0.36363636363636365]\n",
      "[0.3582089552238806, 0.2878787878787879, 0.3181818181818182, 0.3333333333333333, 0.36363636363636365, 0.4406779661016949, 0.4090909090909091, 0.3968253968253968, 0.3389830508474576, 0.4307692307692308, 0.25757575757575757, 0.30303030303030304]\n",
      "[0.3880597014925373, 0.4696969696969697, 0.6363636363636364, 0.696969696969697, 0.5606060606060606, 0.6440677966101694, 0.5151515151515151, 0.6031746031746031, 0.4915254237288136, 0.6307692307692307, 0.5, 0.42424242424242425]\n",
      "[0.23880597014925373, 0.2727272727272727, 0.2878787878787879, 0.3181818181818182, 0.3939393939393939, 0.5084745762711864, 0.3939393939393939, 0.42857142857142855, 0.423728813559322, 0.47692307692307695, 0.4090909090909091, 0.3939393939393939]\n",
      "[0.3283582089552239, 0.24242424242424243, 0.19696969696969696, 0.22727272727272727, 0.24242424242424243, 0.2542372881355932, 0.21212121212121213, 0.2222222222222222, 0.1864406779661017, 0.23076923076923078, 0.24242424242424243, 0.22727272727272727]\n",
      "[0.4925373134328358, 0.5303030303030303, 0.6515151515151515, 0.7575757575757576, 0.4090909090909091, 0.5254237288135594, 0.5757575757575758, 0.49206349206349204, 0.5932203389830508, 0.6461538461538462, 0.5, 0.42424242424242425]\n",
      "[0.40298507462686567, 0.3939393939393939, 0.5303030303030303, 0.5454545454545454, 0.5606060606060606, 0.559322033898305, 0.5151515151515151, 0.5873015873015873, 0.576271186440678, 0.6, 0.45454545454545453, 0.42424242424242425]\n",
      "[0.19402985074626866, 0.24242424242424243, 0.19696969696969696, 0.21212121212121213, 0.21212121212121213, 0.23728813559322035, 0.21212121212121213, 0.19047619047619047, 0.23728813559322035, 0.2153846153846154, 0.22727272727272727, 0.19696969696969696]\n",
      "[0.43283582089552236, 0.5151515151515151, 0.6666666666666666, 0.6666666666666666, 0.5151515151515151, 0.7457627118644068, 0.5454545454545454, 0.5079365079365079, 0.5423728813559322, 0.6615384615384615, 0.3939393939393939, 0.3939393939393939]\n",
      "[0.40298507462686567, 0.4090909090909091, 0.4696969696969697, 0.5, 0.5757575757575758, 0.6440677966101694, 0.45454545454545453, 0.5396825396825397, 0.4915254237288136, 0.5692307692307692, 0.5454545454545454, 0.48484848484848486]\n",
      "[0.208955223880597, 0.36363636363636365, 0.24242424242424243, 0.3484848484848485, 0.15151515151515152, 0.13559322033898305, 0.25757575757575757, 0.31746031746031744, 0.11864406779661017, 0.13846153846153847, 0.22727272727272727, 0.21212121212121213]\n",
      "[0.4626865671641791, 0.45454545454545453, 0.4393939393939394, 0.5151515151515151, 0.48484848484848486, 0.7288135593220338, 0.4393939393939394, 0.36507936507936506, 0.4745762711864407, 0.676923076923077, 0.5757575757575758, 0.3939393939393939]\n",
      "[0.34328358208955223, 0.36363636363636365, 0.5909090909090909, 0.5303030303030303, 0.5, 0.6101694915254238, 0.5, 0.5555555555555556, 0.4745762711864407, 0.676923076923077, 0.48484848484848486, 0.3939393939393939]\n",
      "[0.43283582089552236, 0.3939393939393939, 0.4090909090909091, 0.45454545454545453, 0.5606060606060606, 0.6271186440677966, 0.4393939393939394, 0.5079365079365079, 0.4576271186440678, 0.5076923076923077, 0.4696969696969697, 0.5]\n",
      "[0.3283582089552239, 0.22727272727272727, 0.3484848484848485, 0.42424242424242425, 0.21212121212121213, 0.2711864406779661, 0.25757575757575757, 0.2222222222222222, 0.15254237288135594, 0.26153846153846155, 0.22727272727272727, 0.4090909090909091]\n",
      "[0.34328358208955223, 0.3939393939393939, 0.30303030303030304, 0.4393939393939394, 0.4393939393939394, 0.6440677966101694, 0.4393939393939394, 0.5555555555555556, 0.3728813559322034, 0.5076923076923077, 0.45454545454545453, 0.4090909090909091]\n",
      "[0.44776119402985076, 0.5454545454545454, 0.6060606060606061, 0.696969696969697, 0.4696969696969697, 0.6101694915254238, 0.4696969696969697, 0.49206349206349204, 0.576271186440678, 0.5692307692307692, 0.45454545454545453, 0.4090909090909091]\n",
      "[0.3880597014925373, 0.24242424242424243, 0.24242424242424243, 0.19696969696969696, 0.3333333333333333, 0.2542372881355932, 0.21212121212121213, 0.23809523809523808, 0.23728813559322035, 0.2153846153846154, 0.30303030303030304, 0.3484848484848485]\n",
      "[0.208955223880597, 0.22727272727272727, 0.3181818181818182, 0.4393939393939394, 0.36363636363636365, 0.5423728813559322, 0.42424242424242425, 0.5396825396825397, 0.5254237288135594, 0.5076923076923077, 0.48484848484848486, 0.5]\n",
      "[0.3582089552238806, 0.4393939393939394, 0.5454545454545454, 0.5909090909090909, 0.48484848484848486, 0.6779661016949152, 0.6515151515151515, 0.5238095238095238, 0.4576271186440678, 0.7076923076923077, 0.5909090909090909, 0.4393939393939394]\n",
      "[0.44776119402985076, 0.4696969696969697, 0.45454545454545453, 0.5303030303030303, 0.6060606060606061, 0.6779661016949152, 0.5606060606060606, 0.5714285714285714, 0.5423728813559322, 0.7076923076923077, 0.5303030303030303, 0.4393939393939394]\n",
      "[0.44776119402985076, 0.48484848484848486, 0.5, 0.48484848484848486, 0.5606060606060606, 0.6949152542372882, 0.5454545454545454, 0.5873015873015873, 0.559322033898305, 0.6307692307692307, 0.6060606060606061, 0.5]\n",
      "[0.373134328358209, 0.4696969696969697, 0.48484848484848486, 0.5606060606060606, 0.5909090909090909, 0.6949152542372882, 0.5606060606060606, 0.6031746031746031, 0.559322033898305, 0.6461538461538462, 0.5606060606060606, 0.4393939393939394]\n",
      "[0.3880597014925373, 0.45454545454545453, 0.3939393939393939, 0.4696969696969697, 0.5909090909090909, 0.6949152542372882, 0.5, 0.6031746031746031, 0.5423728813559322, 0.5384615384615384, 0.5909090909090909, 0.48484848484848486]\n",
      " 14%|█▍        | 69/500 [3:41:56<19:08:41, 159.91s/trial, best loss: 0.037453748285770416]"
     ]
    }
   ],
   "source": [
    "EPOCH=1000\n",
    "patience_tone=50\n",
    "\n",
    "stage = 'tone'\n",
    "plot = False\n",
    "verbose = False\n",
    "\n",
    "reporterList=[]\n",
    "def hyperopt_tone(filter_time_length,n_filters,conv_stride,pool_time_length,pool_stride,filter_length,\n",
    "                      n_CNN_layer,gruDim,gruLayer,drop_out):    \n",
    "    \n",
    "    batch_size_tone = 512#batch_size#batch_size,lr,\n",
    "    lr_tone = 0.0005#lr\n",
    "    #batch_size = 8\n",
    "    #lr=0.0005\n",
    "    model2 = timespatCNNRNN(duration=int((tone_back+tone_forward)*hz), typeNum=4, in_chans=len(tone_elecs),\n",
    "                                    is_timespat=True,\n",
    "                                    n_filters_time=n_filters, filter_time_length=filter_time_length,\n",
    "                                    n_filters_spat=n_filters, conv_stride=conv_stride,\n",
    "                                    pool_time_length=pool_time_length, pool_stride=pool_stride,\n",
    "                                    n_filters=n_filters, \n",
    "                                    filter_length=filter_length, \n",
    "                                    n_CNN_layer=n_CNN_layer,\n",
    "                                    gruDim=gruDim,\n",
    "                                    gruLayer=gruLayer,\n",
    "                                    drop_out=drop_out).to(device)\n",
    "\n",
    "    torch.save(model2,(\"./\"+subject+'_tone.pt'))\n",
    "    torch.save(model2,(\"./\"+subject+'.pt'))    \n",
    "\n",
    "    lists,_,_ = CV_train_ENN(CV_datasets = CV_tone_datasets, \n",
    "                                   CV_pred_only_datasets = CV_clip_tone_datasets,\n",
    "                                   lr=lr_tone, batch_size=batch_size_tone, patience=patience_tone,\n",
    "                                   class_weight = class_weight, channelNum=256)\n",
    "    \n",
    "    #a = np.array([np.nanmean(loss_list),is_timespat,batch_size,lr,conv_stride,pool_time_length,pool_stride,filter_length])\n",
    "    a = np.array([np.nanmean(lists[1])+np.nanmean(lists[0]),np.nanmean(lists[1]),np.nanmean(lists[0]),filter_time_length,n_filters,conv_stride,\n",
    "        pool_time_length,pool_stride,filter_length, n_CNN_layer,gruDim,gruLayer,drop_out,])\n",
    "    if verbose:\n",
    "        print(a)\n",
    "    reporterList.append(a)\n",
    "    #print(reporterList)\n",
    "    return(np.nanmean(lists[1])+np.nanmean(lists[0]))\n",
    "    \n",
    "#print(hyperopt_tone())\n",
    "\n",
    "from hyperopt import hp,STATUS_OK,Trials,fmin,tpe\n",
    "def hyperopt_train(params):\n",
    "    loss=hyperopt_tone(**params)\n",
    "    return loss\n",
    "\n",
    "hyperparas = {\n",
    "    #'batch_size': hp.choice('batch_size', [4,8]),\n",
    "    #'lr': hp.choice('lr', [0.0005,0.0001]),\n",
    "    'filter_time_length':hp.choice('filter_time_length', [2,3,5,8]),\n",
    "    'n_filters':hp.choice('n_filters', [16,32,64]),\n",
    "    'conv_stride': hp.choice('conv_stride', [1,2,3]),\n",
    "    'pool_time_length': hp.choice('pool_time_length', [2,3,4]),\n",
    "    'pool_stride': hp.choice('pool_stride', [1,2,3]),\n",
    "    'filter_length': hp.choice('filter_length', [2,3,4]),\n",
    "    'n_CNN_layer':hp.choice('n_CNN_layer',[1,2,3]),\n",
    "    'gruDim':hp.choice('gruDim', [32,64,128]),\n",
    "    'gruLayer':hp.choice('gruLayer',[1,2,3,4]),\n",
    "    'drop_out':hp.choice('drop_out', [0.2,0.3,0.4,0.5,0.6,0.7,0.8]),\n",
    "    #'drop_out':hp.uniform('drop_out', 0.2, 0.8),\n",
    "}\n",
    "#filter_time_length:3\tn_filters:16\tconv_stride:2\tpool_time_length:3\n",
    "#pool_stride:3\tfilter_length:3\tn_CNN_layer:2\tgruDim:32\tgruLayer:3,drop_out:0.633494652\n",
    "\n",
    "def f(params):\n",
    "    '''\n",
    "    loss = hyperopt_train(params)\n",
    "    '''\n",
    "    try:\n",
    "        loss = hyperopt_train(params)\n",
    "    except Exception as e:\n",
    "        # Handle the exception here (e.g., print the error message)\n",
    "        print(f\"Error: {e}\")\n",
    "        # Assign a high loss value to discourage selecting this parameter combination\n",
    "        return {'loss': 9999, 'status': STATUS_OK}\n",
    "    \n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    " \n",
    "trials=Trials()\n",
    "best=fmin(f,hyperparas,algo=tpe.suggest,max_evals=500,trials=trials)\n",
    "\n",
    "print('best',best)\n",
    "\n",
    "\n",
    "'''\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9ea9ba5ae74b1398a630feb3651b8acb263e18aa2ea7db4a76df02121bff196"
  },
  "kernelspec": {
   "display_name": "Python [conda env:test]",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
